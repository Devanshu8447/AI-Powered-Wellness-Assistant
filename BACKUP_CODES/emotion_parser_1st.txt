import os
import uuid
from typing import TypedDict, Annotated
from dotenv import load_dotenv
from datetime import datetime
import sqlite3

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.sqlite import SqliteSaver

from langchain_core.messages import (
    BaseMessage,
    HumanMessage,
    AIMessage,
    SystemMessage as LCSystemMessage,
)

from langchain_groq import ChatGroq

import streamlit as st


# ========================
# Utility functions
# ========================


def generate_thread_id():
    return uuid.uuid4()


def reset_chat():
    thread_id = generate_thread_id()
    st.session_state["thread_id"] = thread_id
    add_thread(thread_id)
    st.session_state["message_history"] = []

    # Initialize chat history store for the new thread
    if "chat_histories" not in st.session_state:
        st.session_state["chat_histories"] = {}
    st.session_state["chat_histories"][thread_id] = []

    # Initialize thread name store if missing
    if "chat_thread_names" not in st.session_state:
        st.session_state["chat_thread_names"] = {}
    # Assign default name based on count and date/time
    count = len(st.session_state["chat_threads"])
    now_str = datetime.now().strftime("%b %d, %Y %H:%M")
    st.session_state["chat_thread_names"][thread_id] = f"Chat {count + 1} - {now_str}"


def load_conversation(thread_id):
    # Returns the messages stored in the LangGraph state/checkpoint
    state = chatbot.get_state(config={"configurable": {"thread_id": thread_id}})
    return state.values.get("messages", [])


def add_thread(thread_id):
    if thread_id not in st.session_state["chat_threads"]:
        st.session_state["chat_threads"].append(thread_id)


def update_chat_name_from_first_message(thread_id, user_message):
    # Update chat name if it currently is the default or empty
    current_name = st.session_state.get("chat_thread_names", {}).get(thread_id, "")
    if current_name.startswith("Chat "):  # Means default name assigned
        snippet = user_message.replace("\n", " ")[:30].strip()
        # Update only if we have valid snippet
        if snippet:
            st.session_state["chat_thread_names"][thread_id] = snippet


# ========================
# Load environment variables
# ========================
load_dotenv()


# ---- Chat state definition ----
class ChatState(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]


# ---- Initialize LLM ----
llm = ChatGroq(model="llama-3.1-8b-instant", temperature=0.7, max_retries=2)


# ---- Chat node ----
def chat_node(state: ChatState):
    system_prompt = (
        "You are a caring, concise mental wellness companion. "
        "Respond empathetically in 2‚Äì5 short sentences. "
        "Offer practical, safe, non-clinical tips. "
        "Do not reveal chain-of-thought or internal reasoning. "
        "If you detect crisis (self-harm/violence), advise contacting local emergency services or hotlines."
    )
    history: list[BaseMessage] = state["messages"]

    # Prepend system prompt if not already present
    if not history or not isinstance(history[0], LCSystemMessage):
        formatted = [LCSystemMessage(content=system_prompt)] + history
    else:
        formatted = history

    # Convert BaseMessage objects to dict format for Groq LLM
    messages_for_groq = []
    for msg in formatted:
        if isinstance(msg, LCSystemMessage):
            role = "system"
        elif isinstance(msg, HumanMessage):
            role = "user"
        elif isinstance(msg, AIMessage):
            role = "assistant"
        else:
            role = "user"
        messages_for_groq.append({"role": role, "content": msg.content})

    # Single-shot invoke (no streaming) to avoid duplicated content chunks
    reply = llm.invoke(messages_for_groq)

    # Extract text content from reply if needed
    if hasattr(reply, "content"):
        reply_text = reply.content
    else:
        reply_text = str(reply)

    # Return the original history plus the *single* AIMessage
    return {"messages": history + [AIMessage(content=reply_text)]}


# ---- Build LangGraph ----
conn = sqlite3.connect(database="chatbot.db", check_same_thread=False)
checkpointer = SqliteSaver(conn=conn)

graph = StateGraph(ChatState)
graph.add_node("chat_node", chat_node)
graph.add_edge(START, "chat_node")
graph.add_edge("chat_node", END)
chatbot = graph.compile(checkpointer=checkpointer)


def retrieve_all_threads():
    all_threads = set()
    for checkpoint in checkpointer.list(None):
        # Each checkpoint contains config with "thread_id"
        all_threads.add(checkpoint.config["configurable"]["thread_id"])
    return list(all_threads)


# =================
# FRONTEND (Streamlit)
# =================


def run_emotion_chat():
    st.subheader("üó£Ô∏è Emotion-Based Chatbot")

    # ---- SESSION SETUP ----
    if "message_history" not in st.session_state:
        st.session_state["message_history"] = []
    if "thread_id" not in st.session_state:
        st.session_state["thread_id"] = generate_thread_id()

    if "chat_threads" not in st.session_state:
        st.session_state["chat_threads"] = retrieve_all_threads()

    add_thread(st.session_state["thread_id"])

    if "chat_thread_names" not in st.session_state:
        st.session_state["chat_thread_names"] = {}

    # Ensure we have a default name for the current thread
    if st.session_state["thread_id"] not in st.session_state["chat_thread_names"]:
        count = len(st.session_state["chat_threads"])
        now_str = datetime.now().strftime("%b %d, %Y %H:%M")
        st.session_state["chat_thread_names"][
            st.session_state["thread_id"]
        ] = f"Chat {count} - {now_str}"

    # Config for LangGraph execution
    CONFIG = {
        "configurable": {"thread_id": st.session_state["thread_id"]},
        "metadata": {"thread_id": st.session_state["thread_id"]},
        "run_name": "chat_run",
    }

    # ---- SIDEBAR UI ----
    st.sidebar.title("LangGraph Chatbot")
    if st.sidebar.button("New Chat"):
        reset_chat()

    st.sidebar.header("My Conversations")
    for thread_id in st.session_state["chat_threads"][::-1]:
        name = st.session_state["chat_thread_names"].get(thread_id, str(thread_id))
        if st.sidebar.button(name, key=f"thread-btn-{thread_id}"):
            st.session_state["thread_id"] = thread_id
            CONFIG = {"configurable": {"thread_id": thread_id}}
            messages = load_conversation(thread_id)

            temp_messages = []
            for message in messages:
                if isinstance(message, HumanMessage):
                    role = "user"
                elif isinstance(message, AIMessage):
                    role = "assistant"
                elif isinstance(message, LCSystemMessage):
                    # Do not show system messages in UI
                    continue
                else:
                    role = "assistant"
                temp_messages.append({"role": role, "content": message.content})

            st.session_state["message_history"] = temp_messages

    # ---- MAIN CHAT HISTORY ----
    for m in st.session_state["message_history"]:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    # ---- User input and response ----
    user_input = st.chat_input("Tell me how you're feeling today...")

    if user_input:
        thread_id = st.session_state["thread_id"]

        # Update chat name based on first message if appropriate
        update_chat_name_from_first_message(thread_id, user_input)

        # Add user message to history (UI only)
        st.session_state["message_history"].append(
            {"role": "user", "content": user_input}
        )
        with st.chat_message("user"):
            st.markdown(user_input)

        # Invoke the LangGraph once (no streaming) to avoid duplicate text
        result_state = chatbot.invoke(
            {"messages": [HumanMessage(content=user_input)]},
            # config={"configurable": {"thread_id": thread_id}},
            # CONFIG={
            #     "configurable": {"thread_id": st.session_state["thread_id"]},
            #     "metadata": {"thread_id": st.session_state["thread_id"]},
            #     "run_name": "chat_run",
            # },
            config=CONFIG,
        )

        # Extract the last AI message from state
        ai_text = ""
        msgs = result_state.get("messages", [])
        if msgs and isinstance(msgs[-1], AIMessage):
            ai_text = msgs[-1].content
        else:
            # Fallback: search from end for first AIMessage
            for msg in reversed(msgs):
                if isinstance(msg, AIMessage):
                    ai_text = msg.content
                    break

        with st.chat_message("assistant"):
            st.markdown(ai_text)

        # Store to UI history once (no duplicates)
        st.session_state["message_history"].append(
            {"role": "assistant", "content": ai_text}
        )


if __name__ == "__main__":
    run_emotion_chat()
